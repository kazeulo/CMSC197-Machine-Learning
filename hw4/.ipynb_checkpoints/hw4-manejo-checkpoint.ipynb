{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcf1d8e4-d19f-44d7-b175-7233c0c43280",
   "metadata": {},
   "source": [
    "### NAIVE BAYES SPAM FILTER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf03cfa-8131-4cf6-8b22-c836134b6d24",
   "metadata": {},
   "source": [
    "#### CMSC 197 Machine Problem 3\n",
    "Manejo, Kzlyr Shaira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "584b1243-5d0c-4053-95a5-4db50387f3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "# for visualization\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "# libraries for preprocessing\n",
    "import os\n",
    "import email\n",
    "import re\n",
    "import codecs\n",
    "from collections import Counter  # for getting frequencies of unique words\n",
    "\n",
    "# for performance evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198ef7ee-07b6-4cb2-8f35-fdd72741fc4a",
   "metadata": {},
   "source": [
    "<b>Preprocessing</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cd18ce-2fc0-4e11-b717-a52c64ab4b8f",
   "metadata": {},
   "source": [
    "For this part, we will prepare the data set by organizing it, cleaning the email contents, and extracting relevant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbab1b0d-ccc8-4e1d-8ab4-83062137a1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'able',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abst',\n",
       " 'accordance',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'across',\n",
       " 'act',\n",
       " 'actually',\n",
       " 'added',\n",
       " 'adj',\n",
       " 'adopted',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affects',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ah',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'an',\n",
       " 'and',\n",
       " 'announce',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anyhow',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'apparently',\n",
       " 'approximately',\n",
       " 'are',\n",
       " 'aren',\n",
       " 'arent',\n",
       " 'arise',\n",
       " 'around',\n",
       " 'as',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asking',\n",
       " 'at',\n",
       " 'auth',\n",
       " 'available',\n",
       " 'away',\n",
       " 'awfully',\n",
       " 'b',\n",
       " 'back',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'beginnings',\n",
       " 'begins',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'believe',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'biol',\n",
       " 'both',\n",
       " 'brief',\n",
       " 'briefly',\n",
       " 'but',\n",
       " 'by',\n",
       " 'c',\n",
       " 'ca',\n",
       " 'came',\n",
       " 'can',\n",
       " 'cannot',\n",
       " \"can't\",\n",
       " 'cause',\n",
       " 'causes',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'co',\n",
       " 'com',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'contain',\n",
       " 'containing',\n",
       " 'contains',\n",
       " 'could',\n",
       " 'couldnt',\n",
       " 'd',\n",
       " 'date',\n",
       " 'did',\n",
       " \"didn't\",\n",
       " 'different',\n",
       " 'do',\n",
       " 'does',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'done',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'downwards',\n",
       " 'due',\n",
       " 'during',\n",
       " 'e',\n",
       " 'each',\n",
       " 'ed',\n",
       " 'edu',\n",
       " 'effect',\n",
       " 'eg',\n",
       " 'eight',\n",
       " 'eighty',\n",
       " 'either',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'end',\n",
       " 'ending',\n",
       " 'enough',\n",
       " 'especially',\n",
       " 'et',\n",
       " 'et-al',\n",
       " 'etc',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everybody',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'ex',\n",
       " 'except',\n",
       " 'f',\n",
       " 'far',\n",
       " 'few',\n",
       " 'ff',\n",
       " 'fifth',\n",
       " 'first',\n",
       " 'five',\n",
       " 'fix',\n",
       " 'followed',\n",
       " 'following',\n",
       " 'follows',\n",
       " 'for',\n",
       " 'former',\n",
       " 'formerly',\n",
       " 'forth',\n",
       " 'found',\n",
       " 'four',\n",
       " 'from',\n",
       " 'further',\n",
       " 'furthermore',\n",
       " 'g',\n",
       " 'gave',\n",
       " 'get',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'give',\n",
       " 'given',\n",
       " 'gives',\n",
       " 'giving',\n",
       " 'go',\n",
       " 'goes',\n",
       " 'gone',\n",
       " 'got',\n",
       " 'gotten',\n",
       " 'h',\n",
       " 'had',\n",
       " 'happens',\n",
       " 'hardly',\n",
       " 'has',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'hed',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " 'heres',\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'hes',\n",
       " 'hi',\n",
       " 'hid',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'hither',\n",
       " 'home',\n",
       " 'how',\n",
       " 'howbeit',\n",
       " 'however',\n",
       " 'hundred',\n",
       " 'i',\n",
       " 'id',\n",
       " 'ie',\n",
       " 'if',\n",
       " \"i'll\",\n",
       " 'im',\n",
       " 'immediate',\n",
       " 'immediately',\n",
       " 'importance',\n",
       " 'important',\n",
       " 'in',\n",
       " 'inc',\n",
       " 'indeed',\n",
       " 'index',\n",
       " 'information',\n",
       " 'instead',\n",
       " 'into',\n",
       " 'invention',\n",
       " 'inward',\n",
       " 'is',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " 'itd',\n",
       " \"it'll\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'j',\n",
       " 'just',\n",
       " 'k',\n",
       " 'keep',\n",
       " 'keeps',\n",
       " 'kept',\n",
       " 'keys',\n",
       " 'kg',\n",
       " 'km',\n",
       " 'know',\n",
       " 'known',\n",
       " 'knows',\n",
       " 'l',\n",
       " 'largely',\n",
       " 'last',\n",
       " 'lately',\n",
       " 'later',\n",
       " 'latter',\n",
       " 'latterly',\n",
       " 'least',\n",
       " 'less',\n",
       " 'lest',\n",
       " 'let',\n",
       " 'lets',\n",
       " 'like',\n",
       " 'liked',\n",
       " 'likely',\n",
       " 'line',\n",
       " 'little',\n",
       " \"'ll\",\n",
       " 'look',\n",
       " 'looking',\n",
       " 'looks',\n",
       " 'ltd',\n",
       " 'm',\n",
       " 'made',\n",
       " 'mainly',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'many',\n",
       " 'may',\n",
       " 'maybe',\n",
       " 'me',\n",
       " 'mean',\n",
       " 'means',\n",
       " 'meantime',\n",
       " 'meanwhile',\n",
       " 'merely',\n",
       " 'mg',\n",
       " 'might',\n",
       " 'million',\n",
       " 'miss',\n",
       " 'ml',\n",
       " 'more',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'mr',\n",
       " 'mrs',\n",
       " 'much',\n",
       " 'mug',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'n',\n",
       " 'na',\n",
       " 'name',\n",
       " 'namely',\n",
       " 'nay',\n",
       " 'nd',\n",
       " 'near',\n",
       " 'nearly',\n",
       " 'necessarily',\n",
       " 'necessary',\n",
       " 'need',\n",
       " 'needs',\n",
       " 'neither',\n",
       " 'never',\n",
       " 'nevertheless',\n",
       " 'new',\n",
       " 'next',\n",
       " 'nine',\n",
       " 'ninety',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'non',\n",
       " 'none',\n",
       " 'nonetheless',\n",
       " 'noone',\n",
       " 'nor',\n",
       " 'normally',\n",
       " 'nos',\n",
       " 'not',\n",
       " 'noted',\n",
       " 'nothing',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'o',\n",
       " 'obtain',\n",
       " 'obtained',\n",
       " 'obviously',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'okay',\n",
       " 'old',\n",
       " 'omitted',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'ones',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'or',\n",
       " 'ord',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'ought',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'outside',\n",
       " 'over',\n",
       " 'overall',\n",
       " 'owing',\n",
       " 'own',\n",
       " 'p',\n",
       " 'page',\n",
       " 'pages',\n",
       " 'part',\n",
       " 'particular',\n",
       " 'particularly',\n",
       " 'past',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'placed',\n",
       " 'please',\n",
       " 'plus',\n",
       " 'poorly',\n",
       " 'possible',\n",
       " 'possibly',\n",
       " 'potentially',\n",
       " 'pp',\n",
       " 'predominantly',\n",
       " 'present',\n",
       " 'previously',\n",
       " 'primarily',\n",
       " 'probably',\n",
       " 'promptly',\n",
       " 'proud',\n",
       " 'provides',\n",
       " 'put',\n",
       " 'q',\n",
       " 'que',\n",
       " 'quickly',\n",
       " 'quite',\n",
       " 'qv',\n",
       " 'r',\n",
       " 'ran',\n",
       " 'rather',\n",
       " 'rd',\n",
       " 're',\n",
       " 'readily',\n",
       " 'really',\n",
       " 'recent',\n",
       " 'recently',\n",
       " 'ref',\n",
       " 'refs',\n",
       " 'regarding',\n",
       " 'regardless',\n",
       " 'regards',\n",
       " 'related',\n",
       " 'relatively',\n",
       " 'research',\n",
       " 'respectively',\n",
       " 'resulted',\n",
       " 'resulting',\n",
       " 'results',\n",
       " 'right',\n",
       " 'run',\n",
       " 's',\n",
       " 'said',\n",
       " 'same',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'saying',\n",
       " 'says',\n",
       " 'sec',\n",
       " 'section',\n",
       " 'see',\n",
       " 'seeing',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'seen',\n",
       " 'self',\n",
       " 'selves',\n",
       " 'sent',\n",
       " 'seven',\n",
       " 'several',\n",
       " 'shall',\n",
       " 'she',\n",
       " 'shed',\n",
       " \"she'll\",\n",
       " 'shes',\n",
       " 'should',\n",
       " \"shouldn't\",\n",
       " 'show',\n",
       " 'showed',\n",
       " 'shown',\n",
       " 'showns',\n",
       " 'shows',\n",
       " 'significant',\n",
       " 'significantly',\n",
       " 'similar',\n",
       " 'similarly',\n",
       " 'since',\n",
       " 'six',\n",
       " 'slightly',\n",
       " 'so',\n",
       " 'some',\n",
       " 'somebody',\n",
       " 'somehow',\n",
       " 'someone',\n",
       " 'somethan',\n",
       " 'something',\n",
       " 'sometime',\n",
       " 'sometimes',\n",
       " 'somewhat',\n",
       " 'somewhere',\n",
       " 'soon',\n",
       " 'sorry',\n",
       " 'specifically',\n",
       " 'specified',\n",
       " 'specify',\n",
       " 'specifying',\n",
       " 'state',\n",
       " 'states',\n",
       " 'still',\n",
       " 'stop',\n",
       " 'strongly',\n",
       " 'sub',\n",
       " 'substantially',\n",
       " 'successfully',\n",
       " 'such',\n",
       " 'sufficiently',\n",
       " 'suggest',\n",
       " 'sup',\n",
       " 'sure',\n",
       " 't',\n",
       " 'take',\n",
       " 'taken',\n",
       " 'taking',\n",
       " 'tell',\n",
       " 'tends',\n",
       " 'th',\n",
       " 'than',\n",
       " 'thank',\n",
       " 'thanks',\n",
       " 'thanx',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'thats',\n",
       " \"that've\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'there',\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " 'thered',\n",
       " 'therefore',\n",
       " 'therein',\n",
       " \"there'll\",\n",
       " 'thereof',\n",
       " 'therere',\n",
       " 'theres',\n",
       " 'thereto',\n",
       " 'thereupon',\n",
       " \"there've\",\n",
       " 'these',\n",
       " 'they',\n",
       " 'theyd',\n",
       " \"they'll\",\n",
       " 'theyre',\n",
       " \"they've\",\n",
       " 'think',\n",
       " 'this',\n",
       " 'those',\n",
       " 'thou',\n",
       " 'though',\n",
       " 'thoughh',\n",
       " 'thousand',\n",
       " 'throug',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'til',\n",
       " 'tip',\n",
       " 'to',\n",
       " 'together',\n",
       " 'too',\n",
       " 'took',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'tried',\n",
       " 'tries',\n",
       " 'truly',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'ts',\n",
       " 'twice',\n",
       " 'two',\n",
       " 'u',\n",
       " 'un',\n",
       " 'under',\n",
       " 'unfortunately',\n",
       " 'unless',\n",
       " 'unlike',\n",
       " 'unlikely',\n",
       " 'until',\n",
       " 'unto',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'ups',\n",
       " 'us',\n",
       " 'use',\n",
       " 'used',\n",
       " 'useful',\n",
       " 'usefully',\n",
       " 'usefulness',\n",
       " 'uses',\n",
       " 'using',\n",
       " 'usually',\n",
       " 'v',\n",
       " 'value',\n",
       " 'various',\n",
       " \"'ve\",\n",
       " 'very',\n",
       " 'via',\n",
       " 'viz',\n",
       " 'vol',\n",
       " 'vols',\n",
       " 'vs',\n",
       " 'w',\n",
       " 'want',\n",
       " 'wants',\n",
       " 'was',\n",
       " \"wasn't\",\n",
       " 'way',\n",
       " 'we',\n",
       " 'wed',\n",
       " 'welcome',\n",
       " \"we'll\",\n",
       " 'went',\n",
       " 'were',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'whatever',\n",
       " \"what'll\",\n",
       " 'whats',\n",
       " 'when',\n",
       " 'whence',\n",
       " 'whenever',\n",
       " 'where',\n",
       " 'whereafter',\n",
       " 'whereas',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " 'wheres',\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'whim',\n",
       " 'whither',\n",
       " 'who',\n",
       " 'whod',\n",
       " 'whoever',\n",
       " 'whole',\n",
       " \"who'll\",\n",
       " 'whom',\n",
       " 'whomever',\n",
       " 'whos',\n",
       " 'whose',\n",
       " 'why',\n",
       " 'widely',\n",
       " 'willing',\n",
       " 'wish',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without',\n",
       " \"won't\",\n",
       " 'words',\n",
       " 'world',\n",
       " 'would',\n",
       " \"wouldn't\",\n",
       " 'www',\n",
       " 'x',\n",
       " 'y',\n",
       " 'yes',\n",
       " 'yet',\n",
       " 'you',\n",
       " 'youd',\n",
       " \"you'll\",\n",
       " 'your',\n",
       " 'youre',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\",\n",
       " 'z',\n",
       " 'zero']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load stop words and store them into a list\n",
    "with open(\"stop_words.txt\",\"r\") as f:\n",
    "    stop_words = f.read().splitlines()\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58bd611b-3a11-460c-800a-2dbf11215d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/000/000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/000/001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/000/002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/000/003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/000/004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37817</th>\n",
       "      <td>../data/126/017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37818</th>\n",
       "      <td>../data/126/018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37819</th>\n",
       "      <td>../data/126/019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37820</th>\n",
       "      <td>../data/126/020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37821</th>\n",
       "      <td>../data/126/021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37822 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             file_path  label\n",
       "0      ../data/000/000      0\n",
       "1      ../data/000/001      1\n",
       "2      ../data/000/002      1\n",
       "3      ../data/000/003      0\n",
       "4      ../data/000/004      1\n",
       "...                ...    ...\n",
       "37817  ../data/126/017      1\n",
       "37818  ../data/126/018      1\n",
       "37819  ../data/126/019      1\n",
       "37820  ../data/126/020      1\n",
       "37821  ../data/126/021      1\n",
       "\n",
       "[37822 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing dictionaries to store paths and labels\n",
    "labels_dict = {'file_path':[], 'label':[]}\n",
    "\n",
    "# read the file for labels \n",
    "with open(\"labels\") as f:\n",
    "    for line in f:\n",
    "        val, key = line.split()\n",
    "        labels_dict['file_path'].append(key.strip())\n",
    "        labels_dict['label'].append(0 if val == 'ham' else 1)\n",
    "\n",
    "# convert to dataframe\n",
    "df_labels = pd.DataFrame.from_dict(labels_dict)\n",
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c796ff13-8203-4ca5-bb4d-ed4abdb18d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean the messages/emails\n",
    "def clean_msg(message):\n",
    "    words = []\n",
    "    for word in message.split():\n",
    "        # remove HTML tags, special characters, and stop words\n",
    "        temp = re.sub('<[^<>]+>', '', word)  \n",
    "        temp = re.sub('[^a-zA-Z]', '', temp) \n",
    "        \n",
    "        # check non-empty and not a stop word\n",
    "        if temp and temp.lower() not in stop_words: \n",
    "            \n",
    "            # convert to lowercase since our stop words are in lowercase\n",
    "            words.append(temp.lower())  \n",
    "            \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a50d2ca-bc44-4ff7-b08b-aae6f9314fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/000/000</td>\n",
       "      <td>0</td>\n",
       "      <td>mailing list queried weeks ago running set arc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/000/001</td>\n",
       "      <td>1</td>\n",
       "      <td>luxury watches buy rolex rolex cartier bvlgari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/000/002</td>\n",
       "      <td>1</td>\n",
       "      <td>academic qualifications prestigious nonacc red...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/000/003</td>\n",
       "      <td>0</td>\n",
       "      <td>greetings verify subscription planfans list ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/000/004</td>\n",
       "      <td>1</td>\n",
       "      <td>chauncey conferred luscious continued tonsillitis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         file_path  label                                    cleaned_message\n",
       "0  ../data/000/000      0  mailing list queried weeks ago running set arc...\n",
       "1  ../data/000/001      1  luxury watches buy rolex rolex cartier bvlgari...\n",
       "2  ../data/000/002      1  academic qualifications prestigious nonacc red...\n",
       "3  ../data/000/003      0  greetings verify subscription planfans list ch...\n",
       "4  ../data/000/004      1  chauncey conferred luscious continued tonsillitis"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here, we clean the messages and merged them with the df_labels to create the main dataframe of our dataset\n",
    "# initialize a list to store cleaned messages\n",
    "cleaned_messages = []\n",
    "\n",
    "# path to the directory containing the email files (replace with your actual path)\n",
    "email_directory = \"dataset/data\"\n",
    "\n",
    "# loop through each file path in the df_labels dataframe\n",
    "for index, row in df_labels.iterrows():\n",
    "    file_path = os.path.join(email_directory, row['file_path'])\n",
    "    \n",
    "    # read and parse the email\n",
    "    with codecs.open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        msg = email.message_from_file(f)\n",
    "        \n",
    "        # extract the email body\n",
    "        if msg.is_multipart():\n",
    "            for part in msg.walk():\n",
    "                content_type = part.get_content_type()\n",
    "                if content_type == 'text/plain':\n",
    "                    body = part.get_payload(decode=True).decode('utf-8', errors='ignore')\n",
    "                    break\n",
    "        else:\n",
    "            body = msg.get_payload(decode=True).decode('utf-8', errors='ignore')\n",
    "\n",
    "    # clean the message using the function above\n",
    "    cleaned_message = clean_msg(body)\n",
    "    cleaned_messages.append(' '.join(cleaned_message))  # join words back to a string to form the message\n",
    "\n",
    "# add the cleaned messages to the dataframe \n",
    "df_labels['cleaned_message'] = cleaned_messages\n",
    "\n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfd8f3bc-ff7e-446f-89a1-65373509e18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/000/000</td>\n",
       "      <td>0</td>\n",
       "      <td>mailing list queried weeks ago running set arc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/000/001</td>\n",
       "      <td>1</td>\n",
       "      <td>luxury watches buy rolex rolex cartier bvlgari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/000/002</td>\n",
       "      <td>1</td>\n",
       "      <td>academic qualifications prestigious nonacc red...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/000/003</td>\n",
       "      <td>0</td>\n",
       "      <td>greetings verify subscription planfans list ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/000/004</td>\n",
       "      <td>1</td>\n",
       "      <td>chauncey conferred luscious continued tonsillitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37817</th>\n",
       "      <td>../data/126/017</td>\n",
       "      <td>1</td>\n",
       "      <td>great news expec ted infinex ventures infx pri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37818</th>\n",
       "      <td>../data/126/018</td>\n",
       "      <td>1</td>\n",
       "      <td>oil sector going crazy weekly gift kkpt thing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37819</th>\n",
       "      <td>../data/126/019</td>\n",
       "      <td>1</td>\n",
       "      <td>httpvdtobjdocscaninfo suffering pain depressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37820</th>\n",
       "      <td>../data/126/020</td>\n",
       "      <td>1</td>\n",
       "      <td>prosperous future increased money earning powe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37821</th>\n",
       "      <td>../data/126/021</td>\n",
       "      <td>1</td>\n",
       "      <td>moat coverall cytochemistry planeload salk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37822 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             file_path  label  \\\n",
       "0      ../data/000/000      0   \n",
       "1      ../data/000/001      1   \n",
       "2      ../data/000/002      1   \n",
       "3      ../data/000/003      0   \n",
       "4      ../data/000/004      1   \n",
       "...                ...    ...   \n",
       "37817  ../data/126/017      1   \n",
       "37818  ../data/126/018      1   \n",
       "37819  ../data/126/019      1   \n",
       "37820  ../data/126/020      1   \n",
       "37821  ../data/126/021      1   \n",
       "\n",
       "                                         cleaned_message  \n",
       "0      mailing list queried weeks ago running set arc...  \n",
       "1      luxury watches buy rolex rolex cartier bvlgari...  \n",
       "2      academic qualifications prestigious nonacc red...  \n",
       "3      greetings verify subscription planfans list ch...  \n",
       "4      chauncey conferred luscious continued tonsillitis  \n",
       "...                                                  ...  \n",
       "37817  great news expec ted infinex ventures infx pri...  \n",
       "37818  oil sector going crazy weekly gift kkpt thing ...  \n",
       "37819  httpvdtobjdocscaninfo suffering pain depressio...  \n",
       "37820  prosperous future increased money earning powe...  \n",
       "37821         moat coverall cytochemistry planeload salk  \n",
       "\n",
       "[37822 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename df_labels to df_main to avoid confusion\n",
    "df_main = df_labels.copy()\n",
    "\n",
    "# now this is our processed dataset\n",
    "df_main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105c0b60-8934-457d-9d8e-9572b5050e1a",
   "metadata": {},
   "source": [
    "<b>Preparing the training and testing sets.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5a2d0a-3f85-4eac-a1be-024e3a812425",
   "metadata": {},
   "source": [
    "For this, we will use folders 000-070 as train set and folders 071-126 as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4947ec42-9648-49a1-9df9-855b5be21fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21300</th>\n",
       "      <td>../data/071/000</td>\n",
       "      <td>1</td>\n",
       "      <td>hesitantly derive perverse satisfaction clodho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21301</th>\n",
       "      <td>../data/071/001</td>\n",
       "      <td>0</td>\n",
       "      <td>things perform experiment display will remain ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21302</th>\n",
       "      <td>../data/071/002</td>\n",
       "      <td>1</td>\n",
       "      <td>best offer month viggra ci ialis vaiium xa naa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21303</th>\n",
       "      <td>../data/071/003</td>\n",
       "      <td>1</td>\n",
       "      <td>de ar wne cr doesnt matter ow real st mmed ia ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21304</th>\n",
       "      <td>../data/071/004</td>\n",
       "      <td>1</td>\n",
       "      <td>special offer adobe video collection adobe pre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file_path  label  \\\n",
       "21300  ../data/071/000      1   \n",
       "21301  ../data/071/001      0   \n",
       "21302  ../data/071/002      1   \n",
       "21303  ../data/071/003      1   \n",
       "21304  ../data/071/004      1   \n",
       "\n",
       "                                         cleaned_message  \n",
       "21300  hesitantly derive perverse satisfaction clodho...  \n",
       "21301  things perform experiment display will remain ...  \n",
       "21302  best offer month viggra ci ialis vaiium xa naa...  \n",
       "21303  de ar wne cr doesnt matter ow real st mmed ia ...  \n",
       "21304  special offer adobe video collection adobe pre...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set\n",
    "df_test = df_main[df_main['file_path'] >= '../data/071']\n",
    "print(\"Testing set\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d01cf9c-0a93-4ecd-b5f2-d0e244497de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam training set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>file_path</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>../data/000/001</td>\n",
       "      <td>1</td>\n",
       "      <td>luxury watches buy rolex rolex cartier bvlgari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>../data/000/002</td>\n",
       "      <td>1</td>\n",
       "      <td>academic qualifications prestigious nonacc red...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>../data/000/004</td>\n",
       "      <td>1</td>\n",
       "      <td>chauncey conferred luscious continued tonsillitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>../data/000/007</td>\n",
       "      <td>1</td>\n",
       "      <td>nbc today body diet beaches magazines hollywoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>../data/000/008</td>\n",
       "      <td>1</td>\n",
       "      <td>oil sector going crazy weekly gift kkpt thing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13772</th>\n",
       "      <td>21294</td>\n",
       "      <td>../data/070/294</td>\n",
       "      <td>1</td>\n",
       "      <td>txtadd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13773</th>\n",
       "      <td>21295</td>\n",
       "      <td>../data/070/295</td>\n",
       "      <td>1</td>\n",
       "      <td>btijclnab binpqnejgmb httpgethighbizez bldb xi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13774</th>\n",
       "      <td>21296</td>\n",
       "      <td>../data/070/296</td>\n",
       "      <td>1</td>\n",
       "      <td>special offer adobe video collection adobe pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13775</th>\n",
       "      <td>21297</td>\n",
       "      <td>../data/070/297</td>\n",
       "      <td>1</td>\n",
       "      <td>doctype html public wcdtd html transitionalen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13776</th>\n",
       "      <td>21299</td>\n",
       "      <td>../data/070/299</td>\n",
       "      <td>1</td>\n",
       "      <td>httptmqmctoverpacenet suffering pain depressio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13777 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index        file_path  label  \\\n",
       "0          1  ../data/000/001      1   \n",
       "1          2  ../data/000/002      1   \n",
       "2          4  ../data/000/004      1   \n",
       "3          7  ../data/000/007      1   \n",
       "4          8  ../data/000/008      1   \n",
       "...      ...              ...    ...   \n",
       "13772  21294  ../data/070/294      1   \n",
       "13773  21295  ../data/070/295      1   \n",
       "13774  21296  ../data/070/296      1   \n",
       "13775  21297  ../data/070/297      1   \n",
       "13776  21299  ../data/070/299      1   \n",
       "\n",
       "                                         cleaned_message  \n",
       "0      luxury watches buy rolex rolex cartier bvlgari...  \n",
       "1      academic qualifications prestigious nonacc red...  \n",
       "2      chauncey conferred luscious continued tonsillitis  \n",
       "3      nbc today body diet beaches magazines hollywoo...  \n",
       "4      oil sector going crazy weekly gift kkpt thing ...  \n",
       "...                                                  ...  \n",
       "13772                                             txtadd  \n",
       "13773  btijclnab binpqnejgmb httpgethighbizez bldb xi...  \n",
       "13774  special offer adobe video collection adobe pre...  \n",
       "13775  doctype html public wcdtd html transitionalen ...  \n",
       "13776  httptmqmctoverpacenet suffering pain depressio...  \n",
       "\n",
       "[13777 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# general train set\n",
    "df_train = df_main[df_main['file_path'] < '../data/071']\n",
    "\n",
    "# for train set of spam\n",
    "df_train_spam = df_train[df_train['label'] == 1]\n",
    "df_train_spam = df_train_spam.reset_index()\n",
    "\n",
    "print(\"Spam training set\")\n",
    "df_train_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fab4990-0809-406e-87c3-16f02b5418c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ham training set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>file_path</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>../data/000/000</td>\n",
       "      <td>0</td>\n",
       "      <td>mailing list queried weeks ago running set arc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>../data/000/003</td>\n",
       "      <td>0</td>\n",
       "      <td>greetings verify subscription planfans list ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>../data/000/005</td>\n",
       "      <td>0</td>\n",
       "      <td>quiet quiet well straw poll plan running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>../data/000/006</td>\n",
       "      <td>0</td>\n",
       "      <td>working departed totally bell labs recommended...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>../data/000/010</td>\n",
       "      <td>0</td>\n",
       "      <td>greetings mass acknowledgement signed planfans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7518</th>\n",
       "      <td>21270</td>\n",
       "      <td>../data/070/270</td>\n",
       "      <td>0</td>\n",
       "      <td>equation generate prime numbers equation theor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519</th>\n",
       "      <td>21271</td>\n",
       "      <td>../data/070/271</td>\n",
       "      <td>0</td>\n",
       "      <td>equation generate prime numbers equation theor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7520</th>\n",
       "      <td>21288</td>\n",
       "      <td>../data/070/288</td>\n",
       "      <td>0</td>\n",
       "      <td>dear dmdx users guidance generating dmdx item ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7521</th>\n",
       "      <td>21293</td>\n",
       "      <td>../data/070/293</td>\n",
       "      <td>0</td>\n",
       "      <td>built handyboard works great testmotor passes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7522</th>\n",
       "      <td>21298</td>\n",
       "      <td>../data/070/298</td>\n",
       "      <td>0</td>\n",
       "      <td>mounted isu infrared demodulator hb realised r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7523 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index        file_path  label  \\\n",
       "0         0  ../data/000/000      0   \n",
       "1         3  ../data/000/003      0   \n",
       "2         5  ../data/000/005      0   \n",
       "3         6  ../data/000/006      0   \n",
       "4        10  ../data/000/010      0   \n",
       "...     ...              ...    ...   \n",
       "7518  21270  ../data/070/270      0   \n",
       "7519  21271  ../data/070/271      0   \n",
       "7520  21288  ../data/070/288      0   \n",
       "7521  21293  ../data/070/293      0   \n",
       "7522  21298  ../data/070/298      0   \n",
       "\n",
       "                                        cleaned_message  \n",
       "0     mailing list queried weeks ago running set arc...  \n",
       "1     greetings verify subscription planfans list ch...  \n",
       "2              quiet quiet well straw poll plan running  \n",
       "3     working departed totally bell labs recommended...  \n",
       "4     greetings mass acknowledgement signed planfans...  \n",
       "...                                                 ...  \n",
       "7518  equation generate prime numbers equation theor...  \n",
       "7519  equation generate prime numbers equation theor...  \n",
       "7520  dear dmdx users guidance generating dmdx item ...  \n",
       "7521  built handyboard works great testmotor passes ...  \n",
       "7522  mounted isu infrared demodulator hb realised r...  \n",
       "\n",
       "[7523 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for train set of ham\n",
    "df_train_ham = df_train[df_train['label'] == 0]\n",
    "df_train_ham = df_train_ham.reset_index()\n",
    "print(\"Ham training set\")\n",
    "df_train_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952620b3-f7f7-4cdc-a00f-1368682b9bd5",
   "metadata": {},
   "source": [
    "<b>Extracting the list of unique words.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f9e490-5549-4bf5-9006-6bc85b9ac0e9",
   "metadata": {},
   "source": [
    "We will get the 1000 most common words only or words with highed frequencies/occurences in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57715d1a-c786-47ed-b514-8cea4136100c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bb</td>\n",
       "      <td>17268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>td</td>\n",
       "      <td>12030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>will</td>\n",
       "      <td>11941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>width</td>\n",
       "      <td>8226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>size</td>\n",
       "      <td>5363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>httpwwwretsiunetptwwwukrnet</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>hrefhttpwwwretsiunetptampwwwukrnetfont</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>emulator</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>caring</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>responds</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        word  frequency\n",
       "0                                         bb      17268\n",
       "1                                         td      12030\n",
       "2                                       will      11941\n",
       "3                                      width       8226\n",
       "4                                       size       5363\n",
       "...                                      ...        ...\n",
       "9995             httpwwwretsiunetptwwwukrnet         21\n",
       "9996  hrefhttpwwwretsiunetptampwwwukrnetfont         21\n",
       "9997                                emulator         21\n",
       "9998                                  caring         21\n",
       "9999                                responds         21\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine messages from the entire df_train dataset\n",
    "all_words = []\n",
    "\n",
    "# process all messages in df_train\n",
    "for msg in df_train['cleaned_message']:\n",
    "    all_words.extend(msg.split())\n",
    "\n",
    "# count occurrences of each word\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "# get the 10,000 most common words and their frequencies\n",
    "most_common_words = word_counts.most_common(10000)\n",
    "\n",
    "# convert to a dataframe\n",
    "df_unique_words = pd.DataFrame(most_common_words, columns=['word', 'frequency'])\n",
    "\n",
    "df_unique_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df63544-77d2-4082-b73c-ee0068ee559a",
   "metadata": {},
   "source": [
    "<b>Creating the feature matrices</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb4ad99-aaf2-4d82-ae9a-6e13b643c1ed",
   "metadata": {},
   "source": [
    "For each word in the dictionary, we will traverse through each file and check its occurrence. If the word exist, we will mark the cell with 1, 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "972f85f3-66c1-44a7-acd1-ec962ce1dd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize feature matrices for spam and ham\n",
    "num_spam = df_train_spam.shape[0]\n",
    "num_ham = df_train_ham.shape[0]\n",
    "dimension = 10000\n",
    "\n",
    "# create an empty matrix\n",
    "matrix_spam = np.zeros((num_spam, dimension), dtype=int)\n",
    "matrix_ham = np.zeros((num_ham, dimension), dtype=int)\n",
    "\n",
    "# create a mapping from words to indices\n",
    "word_index = {word: i for i, (word, _) in enumerate(most_common_words)}\n",
    "\n",
    "# function to fill the feature matrix\n",
    "def fill_feature_matrix(df, matrix, index, column_name):\n",
    "    for i, message in enumerate(df[column_name]):\n",
    "        words = set(message.split())  # use a set to avoid duplicate checks\n",
    "        for word in words:\n",
    "            if word in index:\n",
    "                matrix[i, index[word]] = 1  # mark the occurrence of the word, otherwise the value will be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "673ffb16-218f-481e-8373-5ace60e26a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of spam feature matrix: (13777, 10000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill the spam feature matrix\n",
    "fill_feature_matrix(df_train_spam, matrix_spam, word_index, 'cleaned_message')\n",
    "\n",
    "print(\"Shape of spam feature matrix:\", matrix_spam.shape)\n",
    "matrix_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2201cf1-f0f3-4506-b498-864b51aa8ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of ham feature matrix: (7523, 10000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill the ham matrix\n",
    "fill_feature_matrix(df_train_ham, matrix_ham, word_index, 'cleaned_message')\n",
    "\n",
    "print(\"Shape of ham feature matrix:\", matrix_ham.shape)\n",
    "matrix_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f254beac-c579-4b86-b44e-8580c247f037",
   "metadata": {},
   "source": [
    "<b>Calculating the priors</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bac56fa-ff0b-4c2b-aec0-b348374b9318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_ham:  0.3531924882629108\n",
      "p_spam:  0.6468075117370892\n"
     ]
    }
   ],
   "source": [
    "# compute the prior probabilities for spam and ham\n",
    "n_ham = len(df_train_ham)       # number of ham emails in training set\n",
    "n_spam = len(df_train_spam)     # number of spam emails in training set\n",
    "n_doc = len(df_train)           # number of total emails in training set\n",
    "\n",
    "p_ham = n_ham / n_doc           # divide number of ham emails over the total emails in training set\n",
    "p_spam = n_spam / n_doc         # divide the number of spam emails over the total emails in training set\n",
    "\n",
    "print(\"p_ham: \", p_ham)\n",
    "print(\"p_spam: \", p_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cf70ff-d9f4-41ef-98db-9c5ae6344471",
   "metadata": {},
   "source": [
    "<b>Computing the likelihood of each word.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba1f04bb-3e0a-4265-9c98-1cecd2bf9d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>P(w|ham)</th>\n",
       "      <th>P(w|spam)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bb</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.002165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>td</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.001460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>will</td>\n",
       "      <td>0.006197</td>\n",
       "      <td>0.004816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>width</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.002001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>size</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.002026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Word  P(w|ham)  P(w|spam)\n",
       "0     bb  0.000048   0.002165\n",
       "1     td  0.000038   0.001460\n",
       "2   will  0.006197   0.004816\n",
       "3  width  0.000180   0.002001\n",
       "4   size  0.000552   0.002026"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate probabilities with Laplace smoothing\n",
    "V = len(df_unique_words)\n",
    "\n",
    "# count words in ham and spam classes\n",
    "ham_word_count = np.sum(matrix_ham, axis=0)\n",
    "spam_word_count = np.sum(matrix_spam, axis=0)\n",
    "\n",
    "# total words\n",
    "ham_word_total = np.sum(ham_word_count)\n",
    "spam_word_total = np.sum(spam_word_count)\n",
    "\n",
    "# laplace smoothing parameter\n",
    "a = 1 \n",
    "\n",
    "# initialize dictionaries to store probabilities\n",
    "ham_probabilities = {}\n",
    "spam_probabilities = {}\n",
    "\n",
    "for i in range(V):\n",
    "    word = df_unique_words['word'][i]\n",
    "    \n",
    "    # P(w_i|ham) = (count(w_i,ham) + a) / (total words in ham + a * V)\n",
    "    temp_ham = (ham_word_count[i] + a) / (ham_word_total + a * V)\n",
    "    \n",
    "    # P(w_i|spam) = (count(w_i,spam) + a) / (total words in spam + a * V)\n",
    "    temp_spam = (spam_word_count[i] + a) / (spam_word_total + a * V)\n",
    "    \n",
    "    # assign probabilities to the respective dictionaries\n",
    "    ham_probabilities[word] = temp_ham\n",
    "    spam_probabilities[word] = temp_spam\n",
    "\n",
    "# create a dataframe to display the probabilities\n",
    "df_probabilities = pd.DataFrame({\n",
    "    'Word': df_unique_words['word'],\n",
    "    'P(w|ham)': [ham_probabilities[word] for word in df_unique_words['word']],\n",
    "    'P(w|spam)': [spam_probabilities[word] for word in df_unique_words['word']]\n",
    "})\n",
    "\n",
    "df_probabilities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059ea4e1-7a36-4861-8666-22086b31d628",
   "metadata": {},
   "source": [
    "<b>Classifying the emails</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "940854de-aa1f-4fc7-97c7-8b1542489559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to classify the emails\n",
    "def classify_emails(email, p_ham, p_spam, p_count_ham, p_count_spam, word_list):\n",
    "    # initialize the log values of ham and spam with the log of their prior probabilities\n",
    "    log_p_ham = np.log(p_ham)\n",
    "    log_p_spam = np.log(p_spam)\n",
    "    \n",
    "    # split the cleaned email content into words\n",
    "    words = email.split() \n",
    "    \n",
    "    for w in words:\n",
    "        # add the log probability value if the word is in the word list\n",
    "        if w in word_list:\n",
    "            log_p_ham += np.log(p_count_ham[w])\n",
    "            log_p_spam += np.log(p_count_spam[w])\n",
    "    \n",
    "    # return 0 if the log probability of ham is greater than spam\n",
    "    if log_p_ham > log_p_spam:\n",
    "        return 0  # Ham\n",
    "    else:\n",
    "        return 1  # Spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1171161-a9af-4d10-9cfc-981ff46ca590",
   "metadata": {},
   "source": [
    "<b> Testing the Classifier </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1eadc2c1-f7f6-47a4-97d2-1a625a10cb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize lists to store predictions and actual labels\n",
    "predictions = []\n",
    "actual_labels = df_test['label'].tolist()  # Get actual labels from the test set\n",
    "\n",
    "# classify each email in the test set\n",
    "for message in df_test['cleaned_message']:\n",
    "    prediction = classify_emails(message, p_ham, p_spam, ham_probabilities, spam_probabilities, df_unique_words['word'].tolist())\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5efe194-d7df-4cbc-b556-74fbe93ec64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Path</th>\n",
       "      <th>Actual Label</th>\n",
       "      <th>Predicted Label</th>\n",
       "      <th>Cleaned Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21300</th>\n",
       "      <td>../data/071/000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>hesitantly derive perverse satisfaction clodho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21301</th>\n",
       "      <td>../data/071/001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>things perform experiment display will remain ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21302</th>\n",
       "      <td>../data/071/002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>best offer month viggra ci ialis vaiium xa naa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21303</th>\n",
       "      <td>../data/071/003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>de ar wne cr doesnt matter ow real st mmed ia ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21304</th>\n",
       "      <td>../data/071/004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>special offer adobe video collection adobe pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37817</th>\n",
       "      <td>../data/126/017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>great news expec ted infinex ventures infx pri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37818</th>\n",
       "      <td>../data/126/018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>oil sector going crazy weekly gift kkpt thing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37819</th>\n",
       "      <td>../data/126/019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>httpvdtobjdocscaninfo suffering pain depressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37820</th>\n",
       "      <td>../data/126/020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>prosperous future increased money earning powe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37821</th>\n",
       "      <td>../data/126/021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>moat coverall cytochemistry planeload salk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16522 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             File Path  Actual Label  Predicted Label  \\\n",
       "21300  ../data/071/000             1                1   \n",
       "21301  ../data/071/001             0                0   \n",
       "21302  ../data/071/002             1                1   \n",
       "21303  ../data/071/003             1                1   \n",
       "21304  ../data/071/004             1                1   \n",
       "...                ...           ...              ...   \n",
       "37817  ../data/126/017             1                1   \n",
       "37818  ../data/126/018             1                1   \n",
       "37819  ../data/126/019             1                1   \n",
       "37820  ../data/126/020             1                1   \n",
       "37821  ../data/126/021             1                1   \n",
       "\n",
       "                                         Cleaned Message  \n",
       "21300  hesitantly derive perverse satisfaction clodho...  \n",
       "21301  things perform experiment display will remain ...  \n",
       "21302  best offer month viggra ci ialis vaiium xa naa...  \n",
       "21303  de ar wne cr doesnt matter ow real st mmed ia ...  \n",
       "21304  special offer adobe video collection adobe pre...  \n",
       "...                                                  ...  \n",
       "37817  great news expec ted infinex ventures infx pri...  \n",
       "37818  oil sector going crazy weekly gift kkpt thing ...  \n",
       "37819  httpvdtobjdocscaninfo suffering pain depressio...  \n",
       "37820  prosperous future increased money earning powe...  \n",
       "37821         moat coverall cytochemistry planeload salk  \n",
       "\n",
       "[16522 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe for predictions vs actual labels with file paths and messages\n",
    "results_df = pd.DataFrame({\n",
    "    'File Path': df_test['file_path'],\n",
    "    'Actual Label': actual_labels,\n",
    "    'Predicted Label': predictions,\n",
    "    'Cleaned Message': df_test['cleaned_message']\n",
    "})\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519b588f-015e-434e-84cc-f48dbb70ee46",
   "metadata": {},
   "source": [
    "<b>Performance Evaluation</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c67b5269-6401-4827-808a-0bcb50bc7946",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy:  0.9306379372957269\n",
      "Precision:  0.9779883242415542\n",
      "Recall:  0.9177368657386619\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "df_evaluation = results_df.copy()\n",
    "\n",
    "accuracy = accuracy_score(df_evaluation['Actual Label'], df_evaluation['Predicted Label'])\n",
    "precision = precision_score(df_evaluation['Actual Label'], df_evaluation['Predicted Label'])\n",
    "recall = recall_score(df_evaluation['Actual Label'], df_evaluation['Predicted Label'])\n",
    "\n",
    "# display the results\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dc9fdb4-0671-487b-9467-466123ed87ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positive Rate (FP) - 230\n",
      "False Negative Rate (FN) - 916\n",
      "True Positive Rate (TP) - 10219\n",
      "True Negative Rate (TN) - 5157\n"
     ]
    }
   ],
   "source": [
    "# displaying the confusion matrix\n",
    "conf_matrix = confusion_matrix(df_evaluation['Actual Label'], df_evaluation['Predicted Label'])\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "\n",
    "# plot the confusion matrix\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "print(\"False Positive Rate (FP) - {}\".format(conf_matrix[0][1])) \n",
    "print(\"False Negative Rate (FN) - {}\".format(conf_matrix[1][0])) \n",
    "print(\"True Positive Rate (TP) - {}\".format(conf_matrix[1][1])) \n",
    "print(\"True Negative Rate (TN) - {}\".format(conf_matrix[0][0])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e817a20-1200-4cb6-87ff-fd2592005430",
   "metadata": {},
   "source": [
    "### Results and Discussion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b6728e-ff7f-4c53-b8f8-cb6f31ee8a10",
   "metadata": {},
   "source": [
    "<b>1. What is the effect of removing stop words in terms of precision, recall, and accuracy? Show a plot or a table of these results.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f683e8-f81d-4c26-b2be-9973c48153b1",
   "metadata": {},
   "source": [
    "Let's try a preprocessing where the stop_words are included. Basically, the steps here are just the same with the previous one, excluding only the stop_words on preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd03b462-c59d-4617-9195-f5db54ca86e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean message function\n",
    "def clean_msg(message):\n",
    "    words = []\n",
    "    for word in message.split():\n",
    "        # Remove HTML tags, special characters, and stop words\n",
    "        temp = re.sub('<[^<>]+>', '', word)   \n",
    "        temp = re.sub('[^a-zA-Z]', '', temp)  \n",
    "\n",
    "        # we modified this part and remove the condition that the word should not be included in the stop_words\n",
    "        if temp:  # check non-empty\n",
    "            words.append(temp.lower()) \n",
    "        \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1d7b4ad-7a6c-4764-9395-16cb5b34a8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/000/000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/000/001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/000/002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/000/003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/000/004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37817</th>\n",
       "      <td>../data/126/017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37818</th>\n",
       "      <td>../data/126/018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37819</th>\n",
       "      <td>../data/126/019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37820</th>\n",
       "      <td>../data/126/020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37821</th>\n",
       "      <td>../data/126/021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37822 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             file_path  label\n",
       "0      ../data/000/000      0\n",
       "1      ../data/000/001      1\n",
       "2      ../data/000/002      1\n",
       "3      ../data/000/003      0\n",
       "4      ../data/000/004      1\n",
       "...                ...    ...\n",
       "37817  ../data/126/017      1\n",
       "37818  ../data/126/018      1\n",
       "37819  ../data/126/019      1\n",
       "37820  ../data/126/020      1\n",
       "37821  ../data/126/021      1\n",
       "\n",
       "[37822 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing dictionaries to store paths and labels\n",
    "labels_dict = {'file_path':[], 'label':[]}\n",
    "\n",
    "# read the file for labels \n",
    "with open(\"labels\") as f:\n",
    "    for line in f:\n",
    "        val, key = line.split()\n",
    "        labels_dict['file_path'].append(key.strip())\n",
    "        labels_dict['label'].append(0 if val == 'ham' else 1)\n",
    "\n",
    "# convert to dataframe\n",
    "df_labels = pd.DataFrame.from_dict(labels_dict)\n",
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62ec6502-d622-4013-bc1c-8ac502e25bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_messages_withSW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/000/000</td>\n",
       "      <td>0</td>\n",
       "      <td>the mailing list i queried about a few weeks a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/000/001</td>\n",
       "      <td>1</td>\n",
       "      <td>luxury watches buy your own rolex for only rol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/000/002</td>\n",
       "      <td>1</td>\n",
       "      <td>academic qualifications available from prestig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/000/003</td>\n",
       "      <td>0</td>\n",
       "      <td>greetings all this is to verify your subscript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/000/004</td>\n",
       "      <td>1</td>\n",
       "      <td>try chauncey may conferred the luscious not co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         file_path  label                            cleaned_messages_withSW\n",
       "0  ../data/000/000      0  the mailing list i queried about a few weeks a...\n",
       "1  ../data/000/001      1  luxury watches buy your own rolex for only rol...\n",
       "2  ../data/000/002      1  academic qualifications available from prestig...\n",
       "3  ../data/000/003      0  greetings all this is to verify your subscript...\n",
       "4  ../data/000/004      1  try chauncey may conferred the luscious not co..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean the messages and merged them with the df_labels to create our dataframe\n",
    "# initialize a list to store cleaned messages with stop words\n",
    "cleaned_messages_withSW = []\n",
    "\n",
    "# path to the directory containing the email files\n",
    "email_directory = \"dataset/data\"\n",
    "\n",
    "# loop through each file path in the df_labels DataFrame\n",
    "for index, row in df_labels.iterrows():\n",
    "    file_path = os.path.join(email_directory, row['file_path'])\n",
    "    \n",
    "    # read and parse the email\n",
    "    with codecs.open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        msg = email.message_from_file(f)\n",
    "        \n",
    "        # rxtract the email body (considering different content types)\n",
    "        if msg.is_multipart():\n",
    "            for part in msg.walk():\n",
    "                content_type = part.get_content_type()\n",
    "                if content_type == 'text/plain':\n",
    "                    body = part.get_payload(decode=True).decode('utf-8', errors='ignore')\n",
    "                    break\n",
    "        else:\n",
    "            body = msg.get_payload(decode=True).decode('utf-8', errors='ignore')\n",
    "\n",
    "    # rlean the message using the clean_msg function\n",
    "    cleaned_message = clean_msg(body)\n",
    "    cleaned_messages_withSW.append(' '.join(cleaned_message))  # Join words back to a string\n",
    "\n",
    "# rdd the cleaned messages to the DataFrame\n",
    "df_labels['cleaned_messages_withSW'] = cleaned_messages_withSW\n",
    "\n",
    "# rename df_labels to df_main_SW to avoid confusion\n",
    "df_main_withSW = df_labels.copy()\n",
    "\n",
    "# display the updated DataFrame\n",
    "df_main_withSW.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "254691fc-e6a7-44c2-9afa-117a3198f3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_messages_withSW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21300</th>\n",
       "      <td>../data/071/000</td>\n",
       "      <td>1</td>\n",
       "      <td>where we can hesitantly derive perverse satisf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21301</th>\n",
       "      <td>../data/071/001</td>\n",
       "      <td>0</td>\n",
       "      <td>there are several things you can use to perfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21302</th>\n",
       "      <td>../data/071/002</td>\n",
       "      <td>1</td>\n",
       "      <td>best offer of the month viggra ci ialis vaiium...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21303</th>\n",
       "      <td>../data/071/003</td>\n",
       "      <td>1</td>\n",
       "      <td>de i ar home o h wne n r your cr v ed b it doe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21304</th>\n",
       "      <td>../data/071/004</td>\n",
       "      <td>1</td>\n",
       "      <td>special offer adobe video collection adobe pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37817</th>\n",
       "      <td>../data/126/017</td>\n",
       "      <td>1</td>\n",
       "      <td>great news expec ted infinex ventures inc infx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37818</th>\n",
       "      <td>../data/126/018</td>\n",
       "      <td>1</td>\n",
       "      <td>the oil sector is going crazy this is our week...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37819</th>\n",
       "      <td>../data/126/019</td>\n",
       "      <td>1</td>\n",
       "      <td>httpvdtobjdocscaninfo suffering from pain depr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37820</th>\n",
       "      <td>../data/126/020</td>\n",
       "      <td>1</td>\n",
       "      <td>u n i v e r s i t y d i p l o m a s do you wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37821</th>\n",
       "      <td>../data/126/021</td>\n",
       "      <td>1</td>\n",
       "      <td>but moat coverall be cytochemistry be planeloa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16522 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             file_path  label  \\\n",
       "21300  ../data/071/000      1   \n",
       "21301  ../data/071/001      0   \n",
       "21302  ../data/071/002      1   \n",
       "21303  ../data/071/003      1   \n",
       "21304  ../data/071/004      1   \n",
       "...                ...    ...   \n",
       "37817  ../data/126/017      1   \n",
       "37818  ../data/126/018      1   \n",
       "37819  ../data/126/019      1   \n",
       "37820  ../data/126/020      1   \n",
       "37821  ../data/126/021      1   \n",
       "\n",
       "                                 cleaned_messages_withSW  \n",
       "21300  where we can hesitantly derive perverse satisf...  \n",
       "21301  there are several things you can use to perfor...  \n",
       "21302  best offer of the month viggra ci ialis vaiium...  \n",
       "21303  de i ar home o h wne n r your cr v ed b it doe...  \n",
       "21304  special offer adobe video collection adobe pre...  \n",
       "...                                                  ...  \n",
       "37817  great news expec ted infinex ventures inc infx...  \n",
       "37818  the oil sector is going crazy this is our week...  \n",
       "37819  httpvdtobjdocscaninfo suffering from pain depr...  \n",
       "37820  u n i v e r s i t y d i p l o m a s do you wan...  \n",
       "37821  but moat coverall be cytochemistry be planeloa...  \n",
       "\n",
       "[16522 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set\n",
    "df_test = df_main_withSW[df_main_withSW['file_path'] >= '../data/071']\n",
    "print(\"Testing set\")\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f461589-6722-4309-b143-a1317c5a3990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam training set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>file_path</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_messages_withSW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>../data/000/001</td>\n",
       "      <td>1</td>\n",
       "      <td>luxury watches buy your own rolex for only rol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>../data/000/002</td>\n",
       "      <td>1</td>\n",
       "      <td>academic qualifications available from prestig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>../data/000/004</td>\n",
       "      <td>1</td>\n",
       "      <td>try chauncey may conferred the luscious not co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>../data/000/007</td>\n",
       "      <td>1</td>\n",
       "      <td>from nbc today show its the look everyone want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>../data/000/008</td>\n",
       "      <td>1</td>\n",
       "      <td>the oil sector is going crazy this is our week...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13772</th>\n",
       "      <td>21294</td>\n",
       "      <td>../data/070/294</td>\n",
       "      <td>1</td>\n",
       "      <td>txtadd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13773</th>\n",
       "      <td>21295</td>\n",
       "      <td>../data/070/295</td>\n",
       "      <td>1</td>\n",
       "      <td>btijclnab binpqnejgmb httpgethighbizez bldb xi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13774</th>\n",
       "      <td>21296</td>\n",
       "      <td>../data/070/296</td>\n",
       "      <td>1</td>\n",
       "      <td>special offer adobe video collection adobe pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13775</th>\n",
       "      <td>21297</td>\n",
       "      <td>../data/070/297</td>\n",
       "      <td>1</td>\n",
       "      <td>doctype html public wcdtd html transitionalen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13776</th>\n",
       "      <td>21299</td>\n",
       "      <td>../data/070/299</td>\n",
       "      <td>1</td>\n",
       "      <td>httptmqmctoverpacenet suffering from pain depr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13777 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index        file_path  label  \\\n",
       "0          1  ../data/000/001      1   \n",
       "1          2  ../data/000/002      1   \n",
       "2          4  ../data/000/004      1   \n",
       "3          7  ../data/000/007      1   \n",
       "4          8  ../data/000/008      1   \n",
       "...      ...              ...    ...   \n",
       "13772  21294  ../data/070/294      1   \n",
       "13773  21295  ../data/070/295      1   \n",
       "13774  21296  ../data/070/296      1   \n",
       "13775  21297  ../data/070/297      1   \n",
       "13776  21299  ../data/070/299      1   \n",
       "\n",
       "                                 cleaned_messages_withSW  \n",
       "0      luxury watches buy your own rolex for only rol...  \n",
       "1      academic qualifications available from prestig...  \n",
       "2      try chauncey may conferred the luscious not co...  \n",
       "3      from nbc today show its the look everyone want...  \n",
       "4      the oil sector is going crazy this is our week...  \n",
       "...                                                  ...  \n",
       "13772                                             txtadd  \n",
       "13773  btijclnab binpqnejgmb httpgethighbizez bldb xi...  \n",
       "13774  special offer adobe video collection adobe pre...  \n",
       "13775  doctype html public wcdtd html transitionalen ...  \n",
       "13776  httptmqmctoverpacenet suffering from pain depr...  \n",
       "\n",
       "[13777 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# general train set\n",
    "df_train = df_main_withSW[df_main_withSW['file_path'] < '../data/071']\n",
    "\n",
    "# for train set of spam\n",
    "df_train_spam = df_train[df_train['label'] == 1]\n",
    "df_train_spam = df_train_spam.reset_index()\n",
    "\n",
    "print(\"Spam training set\")\n",
    "df_train_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21767433-3066-43b6-bd45-790772685eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ham training set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>file_path</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_messages_withSW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>../data/000/000</td>\n",
       "      <td>0</td>\n",
       "      <td>the mailing list i queried about a few weeks a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>../data/000/003</td>\n",
       "      <td>0</td>\n",
       "      <td>greetings all this is to verify your subscript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>../data/000/005</td>\n",
       "      <td>0</td>\n",
       "      <td>its quiet too quiet well how about a straw pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>../data/000/006</td>\n",
       "      <td>0</td>\n",
       "      <td>its working here i have departed almost totall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>../data/000/010</td>\n",
       "      <td>0</td>\n",
       "      <td>greetings all this is a mass acknowledgement t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7518</th>\n",
       "      <td>21270</td>\n",
       "      <td>../data/070/270</td>\n",
       "      <td>0</td>\n",
       "      <td>here is an equation that generate all prime nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519</th>\n",
       "      <td>21271</td>\n",
       "      <td>../data/070/271</td>\n",
       "      <td>0</td>\n",
       "      <td>here is an equation that generate all prime nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7520</th>\n",
       "      <td>21288</td>\n",
       "      <td>../data/070/288</td>\n",
       "      <td>0</td>\n",
       "      <td>dear dmdx users i would like guidance in gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7521</th>\n",
       "      <td>21293</td>\n",
       "      <td>../data/070/293</td>\n",
       "      <td>0</td>\n",
       "      <td>hi i built up a handyboard and most of it work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7522</th>\n",
       "      <td>21298</td>\n",
       "      <td>../data/070/298</td>\n",
       "      <td>0</td>\n",
       "      <td>i have mounted the isu infrared demodulator on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7523 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index        file_path  label  \\\n",
       "0         0  ../data/000/000      0   \n",
       "1         3  ../data/000/003      0   \n",
       "2         5  ../data/000/005      0   \n",
       "3         6  ../data/000/006      0   \n",
       "4        10  ../data/000/010      0   \n",
       "...     ...              ...    ...   \n",
       "7518  21270  ../data/070/270      0   \n",
       "7519  21271  ../data/070/271      0   \n",
       "7520  21288  ../data/070/288      0   \n",
       "7521  21293  ../data/070/293      0   \n",
       "7522  21298  ../data/070/298      0   \n",
       "\n",
       "                                cleaned_messages_withSW  \n",
       "0     the mailing list i queried about a few weeks a...  \n",
       "1     greetings all this is to verify your subscript...  \n",
       "2     its quiet too quiet well how about a straw pol...  \n",
       "3     its working here i have departed almost totall...  \n",
       "4     greetings all this is a mass acknowledgement t...  \n",
       "...                                                 ...  \n",
       "7518  here is an equation that generate all prime nu...  \n",
       "7519  here is an equation that generate all prime nu...  \n",
       "7520  dear dmdx users i would like guidance in gener...  \n",
       "7521  hi i built up a handyboard and most of it work...  \n",
       "7522  i have mounted the isu infrared demodulator on...  \n",
       "\n",
       "[7523 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for train set of ham\n",
    "df_train_ham = df_train[df_train['label'] == 0]\n",
    "df_train_ham = df_train_ham.reset_index()\n",
    "print(\"Ham training set\")\n",
    "df_train_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1ed72bd-83c9-47d0-a0ea-0b692356ad76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>137239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to</td>\n",
       "      <td>85210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>73893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>66234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>60293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>bnglojmekmkhzdbpkkhezb</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>bciaedkniuilkngb</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>bnikaldb</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>bhxkevgyeynaldrdbtflkgsb</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>bgpjkimwitbkjksgfkvkblvb</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          word  frequency\n",
       "0                          the     137239\n",
       "1                           to      85210\n",
       "2                            a      73893\n",
       "3                          and      66234\n",
       "4                           of      60293\n",
       "...                        ...        ...\n",
       "9995    bnglojmekmkhzdbpkkhezb         23\n",
       "9996          bciaedkniuilkngb         23\n",
       "9997                  bnikaldb         23\n",
       "9998  bhxkevgyeynaldrdbtflkgsb         23\n",
       "9999  bgpjkimwitbkjksgfkvkblvb         23\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine messages from the entire dataset\n",
    "all_words = []\n",
    "\n",
    "# Process all messages in df_main\n",
    "for msg in df_train['cleaned_messages_withSW']:\n",
    "    all_words.extend(msg.split())\n",
    "\n",
    "# Count occurrences of each word\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "# Get the 10,000 most common words and their frequencies\n",
    "most_common_words = word_counts.most_common(10000)\n",
    "\n",
    "# Convert to a DataFrame for easier analysis\n",
    "df_unique_words = pd.DataFrame(most_common_words, columns=['word', 'frequency'])\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "df_unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f32d502-de28-4e3b-86dd-1fbf610d9e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of spam feature matrix: (13777, 10000)\n",
      "Shape of ham feature matrix: (7523, 10000)\n"
     ]
    }
   ],
   "source": [
    "# initialize feature matrices for spam and ham\n",
    "num_spam = df_train_spam.shape[0]\n",
    "num_ham = df_train_ham.shape[0]\n",
    "dimension = 10000\n",
    "\n",
    "# create an empty matrix\n",
    "matrix_spam = np.zeros((num_spam, dimension), dtype=int)\n",
    "matrix_ham = np.zeros((num_ham, dimension), dtype=int)\n",
    "\n",
    "# create a mapping from words to indices\n",
    "word_index = {word: i for i, (word, _) in enumerate(most_common_words)}\n",
    "\n",
    "# we'll just call the function for filling the matrix\n",
    "# fill the spam feature matrix\n",
    "fill_feature_matrix(df_train_spam, matrix_spam, word_index, 'cleaned_messages_withSW')\n",
    "# fill the ham matrix\n",
    "fill_feature_matrix(df_train_ham, matrix_ham, word_index, 'cleaned_messages_withSW')\n",
    "\n",
    "print(\"Shape of spam feature matrix:\", matrix_spam.shape)\n",
    "print(\"Shape of ham feature matrix:\", matrix_ham.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42b4ff9b-d112-48a9-a5d5-20e5a709d697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_ham:  0.3531924882629108\n",
      "p_spam:  0.6468075117370892\n"
     ]
    }
   ],
   "source": [
    "# prior probabilities which we have already computed above\n",
    "print(\"p_ham: \", p_ham)\n",
    "print(\"p_spam: \", p_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60bb1b1e-4258-4ac1-8a04-641098d4bc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>P(w|ham)</th>\n",
       "      <th>P(w|spam)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>0.009812</td>\n",
       "      <td>0.007818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to</td>\n",
       "      <td>0.009322</td>\n",
       "      <td>0.007853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>0.008678</td>\n",
       "      <td>0.008417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>0.008119</td>\n",
       "      <td>0.007923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>0.007689</td>\n",
       "      <td>0.006417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word  P(w|ham)  P(w|spam)\n",
       "0  the  0.009812   0.007818\n",
       "1   to  0.009322   0.007853\n",
       "2    a  0.008678   0.008417\n",
       "3  and  0.008119   0.007923\n",
       "4   of  0.007689   0.006417"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate probabilities with Laplace smoothing\n",
    "V = len(df_unique_words)\n",
    "\n",
    "# count words in ham and spam classes\n",
    "ham_word_count = np.sum(matrix_ham, axis=0)\n",
    "spam_word_count = np.sum(matrix_spam, axis=0)\n",
    "\n",
    "# total words\n",
    "ham_word_total = np.sum(ham_word_count)\n",
    "spam_word_total = np.sum(spam_word_count)\n",
    "\n",
    "# laplace smoothing parameter\n",
    "a = 1 \n",
    "\n",
    "# initialize dictionaries to store probabilities\n",
    "ham_probabilities = {}\n",
    "spam_probabilities = {}\n",
    "\n",
    "for i in range(V):\n",
    "    word = df_unique_words['word'][i]\n",
    "    \n",
    "    # P(w_i|ham) = (count(w_i,ham) + a) / (total words in ham + a * V)\n",
    "    temp_ham = (ham_word_count[i] + a) / (ham_word_total + a * V)\n",
    "    \n",
    "    # P(w_i|spam) = (count(w_i,spam) + a) / (total words in spam + a * V)\n",
    "    temp_spam = (spam_word_count[i] + a) / (spam_word_total + a * V)\n",
    "    \n",
    "    # Assign probabilities to the respective dictionaries\n",
    "    ham_probabilities[word] = temp_ham\n",
    "    spam_probabilities[word] = temp_spam\n",
    "\n",
    "# create a dataframe to display the probabilities\n",
    "df_probabilities = pd.DataFrame({\n",
    "    'Word': df_unique_words['word'],\n",
    "    'P(w|ham)': [ham_probabilities[word] for word in df_unique_words['word']],\n",
    "    'P(w|spam)': [spam_probabilities[word] for word in df_unique_words['word']]\n",
    "})\n",
    "\n",
    "# display the first few rows of the DataFrame\n",
    "df_probabilities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2ee016-80fe-4291-b787-f2a48a469299",
   "metadata": {},
   "source": [
    "<b>Testing the classifier</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d05cf969-e4fe-482c-97d1-d0403e85f4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize lists to store predictions and actual labels\n",
    "predictions = []\n",
    "actual_labels = df_test['label'].tolist()  # Get actual labels from the test set\n",
    "\n",
    "# classify each email in the test set\n",
    "for message in df_test['cleaned_messages_withSW']:\n",
    "    prediction = classify_emails(message, p_ham, p_spam, ham_probabilities, spam_probabilities, df_unique_words['word'].tolist())\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72bcf42d-65c8-4b94-9ca2-ea9741f627ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Path</th>\n",
       "      <th>Actual Label</th>\n",
       "      <th>Predicted Label</th>\n",
       "      <th>cleaned_messages_withSW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21300</th>\n",
       "      <td>../data/071/000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>where we can hesitantly derive perverse satisf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21301</th>\n",
       "      <td>../data/071/001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>there are several things you can use to perfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21302</th>\n",
       "      <td>../data/071/002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>best offer of the month viggra ci ialis vaiium...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21303</th>\n",
       "      <td>../data/071/003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>de i ar home o h wne n r your cr v ed b it doe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21304</th>\n",
       "      <td>../data/071/004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>special offer adobe video collection adobe pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37817</th>\n",
       "      <td>../data/126/017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>great news expec ted infinex ventures inc infx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37818</th>\n",
       "      <td>../data/126/018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>the oil sector is going crazy this is our week...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37819</th>\n",
       "      <td>../data/126/019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>httpvdtobjdocscaninfo suffering from pain depr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37820</th>\n",
       "      <td>../data/126/020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>u n i v e r s i t y d i p l o m a s do you wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37821</th>\n",
       "      <td>../data/126/021</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>but moat coverall be cytochemistry be planeloa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16522 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             File Path  Actual Label  Predicted Label  \\\n",
       "21300  ../data/071/000             1                1   \n",
       "21301  ../data/071/001             0                0   \n",
       "21302  ../data/071/002             1                1   \n",
       "21303  ../data/071/003             1                1   \n",
       "21304  ../data/071/004             1                1   \n",
       "...                ...           ...              ...   \n",
       "37817  ../data/126/017             1                1   \n",
       "37818  ../data/126/018             1                1   \n",
       "37819  ../data/126/019             1                1   \n",
       "37820  ../data/126/020             1                1   \n",
       "37821  ../data/126/021             1                0   \n",
       "\n",
       "                                 cleaned_messages_withSW  \n",
       "21300  where we can hesitantly derive perverse satisf...  \n",
       "21301  there are several things you can use to perfor...  \n",
       "21302  best offer of the month viggra ci ialis vaiium...  \n",
       "21303  de i ar home o h wne n r your cr v ed b it doe...  \n",
       "21304  special offer adobe video collection adobe pre...  \n",
       "...                                                  ...  \n",
       "37817  great news expec ted infinex ventures inc infx...  \n",
       "37818  the oil sector is going crazy this is our week...  \n",
       "37819  httpvdtobjdocscaninfo suffering from pain depr...  \n",
       "37820  u n i v e r s i t y d i p l o m a s do you wan...  \n",
       "37821  but moat coverall be cytochemistry be planeloa...  \n",
       "\n",
       "[16522 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame for predictions vs actual labels with file paths and messages\n",
    "results_df = pd.DataFrame({\n",
    "    'File Path': df_test['file_path'],\n",
    "    'Actual Label': actual_labels,\n",
    "    'Predicted Label': predictions,\n",
    "    'cleaned_messages_withSW': df_test['cleaned_messages_withSW']\n",
    "})\n",
    "\n",
    "# display the first few rows of the results DataFrame\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40cc0e9a-6a5d-49c2-a747-8a9119695fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy:  0.9064883186054957\n",
      "Precision:  0.9773994424532059\n",
      "Recall:  0.8816344858554108\n"
     ]
    }
   ],
   "source": [
    "# calculate evaluation metrics\n",
    "df_evaluation_withSW = results_df.copy()\n",
    "\n",
    "accuracy_withstopwords = accuracy_score(df_evaluation_withSW['Actual Label'], df_evaluation_withSW['Predicted Label'])\n",
    "precision_withstopwords = precision_score(df_evaluation_withSW['Actual Label'], df_evaluation_withSW['Predicted Label'])\n",
    "recall_withstopwords = recall_score(df_evaluation_withSW['Actual Label'], df_evaluation_withSW['Predicted Label'])\n",
    "\n",
    "# display the results\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(\"Accuracy: \", accuracy_withstopwords)\n",
    "print(\"Precision: \", precision_withstopwords)\n",
    "print(\"Recall: \", recall_withstopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8470f966-e12b-4d5b-821f-a09f4ea5f989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>With Stop Words</th>\n",
       "      <th>Without Stop Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.906488</td>\n",
       "      <td>0.930638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.977399</td>\n",
       "      <td>0.977988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.881634</td>\n",
       "      <td>0.917737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric  With Stop Words  Without Stop Words\n",
       "0   Accuracy         0.906488            0.930638\n",
       "1  Precision         0.977399            0.977988\n",
       "2     Recall         0.881634            0.917737"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets create a dataframe to compare the results\n",
    "results_comparison = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall'],\n",
    "    'With Stop Words': [accuracy_withstopwords, precision_withstopwords, recall_withstopwords],\n",
    "    'Without Stop Words': [accuracy, precision, recall]\n",
    "})\n",
    "\n",
    "results_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5e134fe-40e6-40d9-a490-cbf3025e262f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the values for better visualization\n",
    "results_comparison.plot(kind='bar', figsize=(7, 4))\n",
    "plt.title('Comparison of Classifier Performance')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y')\n",
    "plt.legend(title='Condition')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e8ec3c-6cfe-4ba4-83ca-a0072c380a99",
   "metadata": {},
   "source": [
    "As we can see above, the performance of our classifier when stop words are removed is higher compared when the stop words are included. From this, we can infer that removing the stop words can improve the performance of the model or classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ec37da-a68c-4ed3-aedf-4dfaf83de4e1",
   "metadata": {},
   "source": [
    "<b>2. Experiment on the number of words used for training to include words occurring 50, 100, and 1000 times¶</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbec78b-e9a4-439e-b31e-61c43c9d24e6",
   "metadata": {},
   "source": [
    "In this part, we will filter the word list based on their frequency of occurrence. We will use varying thresholds where k = [1000, 100, 50]. The process is just the same as the above but I will be simplifying it here to make it shorter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4c5559-e7ae-4ba0-8c06-7fa86661a1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll get the unique words from the cleaned messages without stopwords\n",
    "# combine messages from the entire df_train dataset\n",
    "all_words = []\n",
    "\n",
    "# process all messages in df_train\n",
    "for msg in df_train['cleaned_message']:\n",
    "    all_words.extend(msg.split())\n",
    "\n",
    "# count occurrences of each word\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "# get the 10,000 most common words and their frequencies\n",
    "most_common_words = word_counts.most_common(10000)\n",
    "\n",
    "# convert to a dataframe\n",
    "df_unique_words = pd.DataFrame(most_common_words, columns=['word', 'frequency'])\n",
    "\n",
    "df_unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f96f21f-3ef8-4837-8557-444512bef20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will also use the first main dataframe we have, the one without stopwords\n",
    "df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e88ded-6052-4d66-9c1c-4efec57f2cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define thresholds for filtering\n",
    "thresholds = [1000, 100, 50]\n",
    "\n",
    "# initialize a dictionary to store results for each threshold\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd31371-a5fd-4836-9336-b19d723f150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data again\n",
    "# test set\n",
    "df_test = df_main[df_main['file_path'] >= '../data/071']\n",
    "\n",
    "# general train set\n",
    "df_train = df_main[df_main['file_path'] < '../data/071']\n",
    "\n",
    "# for train set of spam\n",
    "df_train_spam = df_train[df_train['label'] == 1]\n",
    "df_train_spam = df_train_spam.reset_index()\n",
    "\n",
    "# for train set of ham\n",
    "df_train_ham = df_train[df_train['label'] == 0]\n",
    "df_train_ham = df_train_ham.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb08bac0-3b4c-497d-b31d-31d13aed1340",
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in thresholds:\n",
    "    # filter the unique words based on the threshold\n",
    "    filtered_words = df_unique_words[df_unique_words['frequency'] >= threshold]['word'].tolist()\n",
    "    V_filtered = len(filtered_words)  # number of unique words after filtering\n",
    "\n",
    "    # create new feature matrices for spam and ham with filtered words\n",
    "    matrix_spam_filtered = np.zeros((num_spam, V_filtered), dtype=int)\n",
    "    matrix_ham_filtered = np.zeros((num_ham, V_filtered), dtype=int)\n",
    "\n",
    "    # create a mapping from filtered words to indices\n",
    "    word_index_filtered = {word: i for i, word in enumerate(filtered_words)}\n",
    "\n",
    "    # fill the feature matrices using the filtered words\n",
    "    fill_feature_matrix(df_train_spam, matrix_spam_filtered, word_index_filtered, 'cleaned_message')\n",
    "    fill_feature_matrix(df_train_ham, matrix_ham_filtered, word_index_filtered, 'cleaned_message')\n",
    "\n",
    "    # count words in ham and spam classes\n",
    "    ham_word_count_filtered = np.sum(matrix_ham_filtered, axis=0)\n",
    "    spam_word_count_filtered = np.sum(matrix_spam_filtered, axis=0)\n",
    "\n",
    "    # total words in ham and spam classes\n",
    "    ham_word_total_filtered = np.sum(ham_word_count_filtered)\n",
    "    spam_word_total_filtered = np.sum(spam_word_count_filtered)\n",
    "\n",
    "    # calculate probabilities with Laplace smoothing for filtered words\n",
    "    ham_probabilities_filtered = {}\n",
    "    spam_probabilities_filtered = {}\n",
    "\n",
    "    for word in filtered_words:\n",
    "        temp_ham = (ham_word_count_filtered[word_index_filtered[word]] + a) / (ham_word_total_filtered + a * V_filtered)\n",
    "        temp_spam = (spam_word_count_filtered[word_index_filtered[word]] + a) / (spam_word_total_filtered + a * V_filtered)\n",
    "        \n",
    "        ham_probabilities_filtered[word] = temp_ham\n",
    "        spam_probabilities_filtered[word] = temp_spam\n",
    "\n",
    "    # Classify emails in the test set using the filtered probabilities\n",
    "    predictions_filtered = []\n",
    "\n",
    "    for message in df_test['cleaned_message']:\n",
    "        prediction = classify_emails(message, p_ham, p_spam, ham_probabilities_filtered, spam_probabilities_filtered, filtered_words)\n",
    "        predictions_filtered.append(prediction)\n",
    "\n",
    "    # Evaluate results\n",
    "    accuracy = accuracy_score(df_test['label'], predictions_filtered)\n",
    "    precision = precision_score(df_test['label'], predictions_filtered)\n",
    "    recall = recall_score(df_test['label'], predictions_filtered)\n",
    "\n",
    "    results[threshold] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d01e90-22a7-4203-b4aa-115c80192645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the results\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df.columns = ['Accuracy', 'Precision', 'Recall']\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880e7a18-933a-4013-a77a-37ef9189637a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the performance metrics for better visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# accuracy\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.bar(results_df.index.astype(str), results_df['Accuracy'], color='blue')\n",
    "plt.title('Accuracy by Word Frequency Threshold')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# precision\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.bar(results_df.index.astype(str), results_df['Precision'], color='orange')\n",
    "plt.title('Precision by Word Frequency Threshold')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Precision')\n",
    "\n",
    "# recall\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.bar(results_df.index.astype(str), results_df['Recall'], color='green')\n",
    "plt.title('Recall by Word Frequency Threshold')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Recall')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23a18da-1c24-434b-9e73-5864552a5db3",
   "metadata": {},
   "source": [
    "Based on the result, it can be noted that lower threshold, such as 50 and 100, can improve the performance of the model compared to a higher threshold or 1000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fa9ebb-9b69-4f08-a52b-3d956a827807",
   "metadata": {},
   "source": [
    "<b>3. Using different parameters for Lambda smoothing where = 2.0, 1.0, 0.5, 0.1, 0.005</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b477336-9681-42e9-8123-28089eb135d5",
   "metadata": {},
   "source": [
    "For this part, I will also be using the data where the stop words is not included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb7283f-dfb5-460a-b083-1479a2b3824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of lambda values to test\n",
    "lambda_values = [2.0, 1.0, 0.5, 0.1, 0.005]\n",
    "\n",
    "evaluation_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f890b007-8583-49f9-9179-0b8164ee3f1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Classify each email in the test set using the current lambda value\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_message\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m---> 24\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m classify_emails(message, p_ham, p_spam, ham_probabilities, spam_probabilities, df_unique_words[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m     25\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(prediction)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Calculate evaluation metrics\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[16], line 14\u001b[0m, in \u001b[0;36mclassify_emails\u001b[1;34m(email, p_ham, p_spam, p_count_ham, p_count_spam, word_list)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m word_list:\n\u001b[0;32m     13\u001b[0m         log_p_ham \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(p_count_ham[w])\n\u001b[1;32m---> 14\u001b[0m         log_p_spam \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(p_count_spam[w])\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# return 0 if the log probability of ham is greater than spam\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m log_p_ham \u001b[38;5;241m>\u001b[39m log_p_spam:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for a in lambda_values:\n",
    "    # Calculate probabilities with Laplace smoothing for current lambda value\n",
    "    ham_probabilities = {}\n",
    "    spam_probabilities = {}\n",
    "\n",
    "    for i in range(V):\n",
    "        word = df_unique_words['word'][i]\n",
    "        \n",
    "        # P(w_i|ham) = (count(w_i,ham) + a) / (total words in ham + a * V)\n",
    "        temp_ham = (ham_word_count[i] + a) / (ham_word_total + a * V)\n",
    "        \n",
    "        # P(w_i|spam) = (count(w_i,spam) + a) / (total words in spam + a * V)\n",
    "        temp_spam = (spam_word_count[i] + a) / (spam_word_total + a * V)\n",
    "        \n",
    "        # assign probabilities to the respective dictionaries\n",
    "        ham_probabilities[word] = temp_ham\n",
    "        spam_probabilities[word] = temp_spam\n",
    "\n",
    "    # Initialize lists to store predictions\n",
    "    predictions = []\n",
    "\n",
    "    # Classify each email in the test set using the current lambda value\n",
    "    for message in df_test['cleaned_message']:\n",
    "        prediction = classify_emails(message, p_ham, p_spam, ham_probabilities, spam_probabilities, df_unique_words['word'].tolist())\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(df_test['label'], predictions)\n",
    "    precision = precision_score(df_test['label'], predictions)\n",
    "    recall = recall_score(df_test['label'], predictions)\n",
    "\n",
    "    # Store results for the current lambda value\n",
    "    evaluation_results[a] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb04a437-6151-4879-b9df-d5b2b54d1031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the results for each lambda value\n",
    "for lambda_val, metrics in evaluation_results.items():\n",
    "    print(f\"Results for λ = {lambda_val}\")\n",
    "    print(f\"Accuracy: {metrics['Accuracy']}\")\n",
    "    print(f\"Precision: {metrics['Precision']\")\n",
    "    print(f\"Recall: {metrics['Recall']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a027e4-5bfb-45cd-aa91-9030cc0a684e",
   "metadata": {},
   "source": [
    "<b>4. Recommendations to improve the model</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a87d4da-8a43-47a5-a669-e1410749d208",
   "metadata": {},
   "source": [
    "Based from the results of experimentations, removing nonsensical words can really improve the performance of the classifier in terms of accuracy, precision, and recall.This improvement can be attributed to the fact that the model can focus more on relevant features from the data, allowing it to learn more effectively. Additionally, using smaller number of vocabulary or words can lead to a better model performance. By limiting the number of words, for example 50, we reduce noise, allowing the classifier to concentrate on relevant features. Moreover, employing higher values of the lambda for Laplace smoothing can also positively impact the model's performance. In summary, we can follow these strategies - removing nonsensical words, using smaller number of words and higher values of lambda to further improve the overall performance of the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
